{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from scipy.signal import iirnotch, filtfilt\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from src.gaussian_funcs import gaussian_function, compute_gauss_std, calc_r_squared\n",
    "from src.utils import create_subject_file_mapping, extract_data, extract_metadata, compute_knee_frequency, compute_time_constant\n",
    "from src.processing import simulate_ecg_signal, average_fft_of_epochs_loglog, extract_control_points, find_most_similar_signal, create_peak_params, get_peak_indices\n",
    "from src.analysis import epoch_signals, find_extremum, estimate_fwhm, find_peak_boundaries, generate_histograms\n",
    "\n",
    "from scipy.signal import detrend, butter, filtfilt, welch\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from fooof import FOOOF\n",
    "\n",
    "import multiprocessing as mp\n",
    "import time\n",
    "\n",
    "\n",
    "#FS = sampling rate; The sampling frequency of `ecg_signal` (in Hz, i.e., samples/second).\n",
    "FS = 1000\n",
    "sampling_rate = 1000\n",
    "\n",
    "CROP_MIN = 1000\n",
    "CROP_MAX = 3000\n",
    "WINDOW_LENGTH = 5000\n",
    "\n",
    "FWHM_Q_IND = 5\n",
    "FWHM_S_IND = 5\n",
    "STD_R_HEIGHT = 10\n",
    "\n",
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sharpness calculation function using the derivative, normalized by peak amplitude\n",
    "def calculate_sharpness_deriv(sig, peak_index, window_size=15):\n",
    "    # Extract a segment of the signal centered on the peak\n",
    "    cropped_peak_sig = sig[max(0, peak_index - window_size): min(len(sig) - 1, peak_index + window_size + 1)]\n",
    "    # Compute the first derivative of the segment\n",
    "    derivative = np.abs(np.diff(cropped_peak_sig))\n",
    "    # Calculate the mean of the absolute values of the derivative\n",
    "    sharpness_deriv = np.mean(derivative)\n",
    "    return sharpness_deriv\n",
    "\n",
    "# Path to the directory containing the raw data files\n",
    "dir_path = '/Users/morganfitzgerald/Projects/ecg_param/data/raw'\n",
    "files_dat_dict, files_hea_dict = create_subject_file_mapping(dir_path)\n",
    "results_dir = '../docs/saved_files/timedomain_results/'\n",
    "\n",
    "\n",
    "def process_subject(SUB_NUM, dat_path, hea_path, results_dir):\n",
    "    start_time = time.time()\n",
    "    print(f'Processing subject {SUB_NUM}')\n",
    "    try:\n",
    "        # Load the current subject's data using the .dat and .hea file paths\n",
    "        sigs, metadata = extract_data(\n",
    "            dat_path,  # Path to the .dat file for the current subject\n",
    "            hea_path,  # Path to the .hea file for the current subject\n",
    "            raw_dtype='int16'\n",
    "        )\n",
    "\n",
    "        # SELECT THE SIGNAL\n",
    "        template_ecg = simulate_ecg_signal(duration=5, sampling_rate=1000, heart_rate=80, amplitude_factor=7, normalize=False)\n",
    "        normalized_signals = []\n",
    "\n",
    "        for ind in range(metadata['n_sigs']):\n",
    "            signal_name = metadata[f'sig{str(ind).zfill(2)}']['signal_name']\n",
    "            if signal_name == 'NIBP':\n",
    "                continue\n",
    "            cropped_signal = sigs[ind][CROP_MIN:CROP_MAX]\n",
    "            normalized_signal = (cropped_signal - np.mean(cropped_signal)) / np.std(cropped_signal)\n",
    "            normalized_signals.append(normalized_signal)\n",
    "\n",
    "        selected_signal, selected_signal_name, selected_signal_index = find_most_similar_signal(template_ecg, normalized_signals, metadata)\n",
    "        ecg = sigs[selected_signal_index]\n",
    "\n",
    "        # High-pass filter\n",
    "        cutoff_frequency = 0.05  # Set your desired cutoff frequency in Hz\n",
    "        order = 4  # Set the filter order\n",
    "        b, a = butter(order, cutoff_frequency, btype='high', analog=False, fs=metadata['fs'])\n",
    "        ecg_hp = filtfilt(b, a, ecg)\n",
    "\n",
    "        # Notch filtering\n",
    "        fs = metadata['fs']  # Sampling rate\n",
    "        f0 = 50  # Line noise frequency (50 Hz)\n",
    "        quality_factor = 30  # Quality factor, determines bandwidth around f0\n",
    "        b, a = iirnotch(f0, quality_factor, fs)\n",
    "        ecg_notch = filtfilt(b, a, ecg_hp)\n",
    "\n",
    "        # Neurokit Cleaning\n",
    "        ecg_clean_nk = nk.ecg_clean(ecg, sampling_rate=1000)\n",
    "        p_peaks_nk, rpeaks_nk, waves_nk = extract_control_points(ecg_clean_nk, sampling_rate)\n",
    "        epochs_nk_df, _ = epoch_signals(p_peaks_nk, ecg_clean_nk, FS, SUB_NUM, PLOT=False, SAVE=False)\n",
    "\n",
    "        # Epoch and Detrend Sig\n",
    "        epochs_df, result_r_latencies = epoch_signals(p_peaks_nk, ecg_notch, FS, SUB_NUM, PLOT=False, SAVE=False)\n",
    "\n",
    "        # PARAMETERIZATION LOOP: Fit Gaussians\n",
    "        num_cycles = len(epochs_df['cycle'].unique())\n",
    "\n",
    "        # Create the dictionary\n",
    "        ecg_output_dict = {\n",
    "            \"cycle\": np.arange(0, num_cycles).tolist(),\n",
    "            \"p_center\": np.zeros(num_cycles).tolist(),\n",
    "            \"p_height\": np.zeros(num_cycles).tolist(),\n",
    "            \"p_width\": np.zeros(num_cycles).tolist(),\n",
    "            \"q_center\": np.zeros(num_cycles).tolist(),\n",
    "            \"q_height\": np.zeros(num_cycles).tolist(),\n",
    "            \"q_width\": np.zeros(num_cycles).tolist(),\n",
    "            \"r_center\": np.zeros(num_cycles).tolist(),\n",
    "            \"r_height\": np.zeros(num_cycles).tolist(),\n",
    "            \"r_width\": np.zeros(num_cycles).tolist(),\n",
    "            \"s_center\": np.zeros(num_cycles).tolist(),\n",
    "            \"s_height\": np.zeros(num_cycles).tolist(),\n",
    "            \"s_width\": np.zeros(num_cycles).tolist(),\n",
    "            \"t_center\": np.zeros(num_cycles).tolist(),\n",
    "            \"t_height\": np.zeros(num_cycles).tolist(),\n",
    "            \"t_width\": np.zeros(num_cycles).tolist(),\n",
    "            \"r_squared\": np.zeros(num_cycles).tolist(),\n",
    "            \"pr_interval\": np.zeros(num_cycles).tolist(),\n",
    "            \"pr_segment\": np.zeros(num_cycles).tolist(),\n",
    "            \"qrs_duration\": np.zeros(num_cycles).tolist(),\n",
    "            \"st_segment\": np.zeros(num_cycles).tolist(),\n",
    "            \"qt_interval\": np.zeros(num_cycles).tolist(),\n",
    "            \"p_duration\": np.zeros(num_cycles).tolist(),\n",
    "            \"pp_interval\": np.zeros(num_cycles).tolist(),\n",
    "            \"rr_interval\": np.zeros(num_cycles).tolist(),\n",
    "            \"fwhm_p\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_time_p\": np.zeros(num_cycles).tolist(),\n",
    "            \"decay_time_p\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_decay_symmetry_p\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_deriv_p\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_diff_p\": np.zeros(num_cycles).tolist(),\n",
    "            \"fwhm_q\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_time_q\": np.zeros(num_cycles).tolist(),\n",
    "            \"decay_time_q\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_decay_symmetry_q\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_deriv_q\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_diff_q\": np.zeros(num_cycles).tolist(),\n",
    "            \"fwhm_r\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_time_r\": np.zeros(num_cycles).tolist(),\n",
    "            \"decay_time_r\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_decay_symmetry_r\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_deriv_r\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_diff_r\": np.zeros(num_cycles).tolist(),\n",
    "            \"fwhm_s\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_time_s\": np.zeros(num_cycles).tolist(),\n",
    "            \"decay_time_s\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_decay_symmetry_s\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_deriv_s\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_diff_s\": np.zeros(num_cycles).tolist(),\n",
    "            \"fwhm_t\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_time_t\": np.zeros(num_cycles).tolist(),\n",
    "            \"decay_time_t\": np.zeros(num_cycles).tolist(),\n",
    "            \"rise_decay_symmetry_t\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_deriv_t\": np.zeros(num_cycles).tolist(),\n",
    "            \"sharpness_diff_t\": np.zeros(num_cycles).tolist(),\n",
    "            \"Average_Heart_Rate\": np.zeros(num_cycles).tolist(),\n",
    "            \"SDNN\": np.zeros(num_cycles).tolist(),\n",
    "            \"RMSSD\": np.zeros(num_cycles).tolist(),\n",
    "            \"NN50\": np.zeros(num_cycles).tolist(),\n",
    "        }\n",
    "\n",
    "        # Initialize variables to hold the previous peaks' locations\n",
    "        previous_r_center = None\n",
    "        previous_p_center = None\n",
    "\n",
    "        # Ensure on and off keys are initialized\n",
    "        for comp in ['p', 'q', 'r', 's', 't']:\n",
    "            ecg_output_dict[f'{comp}_on'] = [np.nan] * num_cycles\n",
    "            ecg_output_dict[f'{comp}_off'] = [np.nan] * num_cycles\n",
    "\n",
    "        for cycle in np.arange(0, num_cycles):\n",
    "\n",
    "            print(f\"Parameterizing cycle #{cycle}.\")\n",
    "            one_cycle = epochs_df.loc[epochs_df['cycle'] == cycle]\n",
    "\n",
    "            if one_cycle.empty:\n",
    "                print(f'cycle #{cycle} is empty')\n",
    "                continue\n",
    "\n",
    "            if one_cycle['signal_y'].isnull().values.any():\n",
    "                print(f'cycle #{cycle} has NaNs')\n",
    "                continue\n",
    "\n",
    "            # X values and Y values with offset correction\n",
    "            xs = np.arange(one_cycle['index'].iloc[0], one_cycle['index'].iloc[-1] + 1)\n",
    "            sig = np.asarray(one_cycle['signal_y'])\n",
    "            sig_flat = detrend(sig)\n",
    "            sig = sig_flat - np.mean(sig_flat[0:25])\n",
    "\n",
    "            ##### Defining R guesses first #####\n",
    "            r_ind = np.argmax(sig)\n",
    "            r_height = sig[r_ind]\n",
    "            r_center = xs[r_ind]\n",
    "\n",
    "            half_r_height = 0.5 * r_height\n",
    "            le_ind_r, ri_ind_r = find_peak_boundaries(sig, r_ind, peak_height=r_height)\n",
    "\n",
    "            # Use estimate_fwhm to calculate the FWHM based on the left and right indices\n",
    "            fwhm_r = estimate_fwhm(le_ind_r, ri_ind_r, r_ind)\n",
    "\n",
    "            # Check if FWHM calculation was successful\n",
    "            if fwhm_r is None:\n",
    "                print(f\"Cycle #{cycle} could not estimate FWHM.\")\n",
    "                continue\n",
    "\n",
    "            # #### Now define rest of component guesses ####     \n",
    "            # Finding P, Q, S, T components\n",
    "            q_min_ind = int(r_ind - (FWHM_Q_IND * fwhm_r))\n",
    "            q_ind, q_height, q_center = find_extremum(sig, xs, q_min_ind, r_ind, mode='min')\n",
    "            p_ind, p_height, p_center = find_extremum(sig, xs, 0, q_ind, mode='max')\n",
    "            s_max_ind = int(r_ind + (FWHM_S_IND * fwhm_r))\n",
    "            s_ind, s_height, s_center = find_extremum(sig, xs, r_ind, s_max_ind, mode='min')\n",
    "            t_ind, t_height, t_center = find_extremum(sig, xs, s_ind, len(sig), mode='max')\n",
    "\n",
    "            # Organizing component information\n",
    "            component_inds = {\n",
    "                'p': [p_ind, p_height, p_center],\n",
    "                'q': [q_ind, q_height, q_center],\n",
    "                'r': [r_ind, r_height, r_center],\n",
    "                's': [s_ind, s_height, s_center],\n",
    "                't': [t_ind, t_height, t_center]\n",
    "            }\n",
    "\n",
    "            # Initialize matrix of guess parameters for gaussian fitting\n",
    "            guess = np.empty([0, 3])\n",
    "\n",
    "            # Skip cycle if any of the expected positive components are negative\n",
    "            if component_inds['p'][1] < 0:\n",
    "                print(f\"cycle #{cycle}'s p component is negative\")\n",
    "                continue\n",
    "            if component_inds['r'][1] < 0:\n",
    "                print(f\"cycle #{cycle}'s r component is negative\")\n",
    "                continue\n",
    "            if component_inds['t'][1] < 0:\n",
    "                print(f\"cycle #{cycle}'s t component is negative\")\n",
    "                continue\n",
    "\n",
    "            for comp, params in component_inds.items():\n",
    "                # Directly use the find_peak_boundaries function with peak_height parameter\n",
    "                onset, offset = find_peak_boundaries(sig, peak_index=params[0], peak_height=params[1])\n",
    "\n",
    "                # Store the onset and offset values in the dictionary\n",
    "                ecg_output_dict[f'{comp}_on'][cycle] = xs[onset] if onset is not None else np.nan\n",
    "                ecg_output_dict[f'{comp}_off'][cycle] = xs[offset] if offset is not None else np.nan\n",
    "\n",
    "                # Guess bandwidth procedure: estimate the width of the peak\n",
    "                if onset is not None and offset is not None:\n",
    "                    short_side = min(abs(params[0] - onset), abs(offset - params[0]))\n",
    "                else:\n",
    "                    short_side = 0\n",
    "\n",
    "                fwhm = short_side * 2\n",
    "                guess_std = compute_gauss_std(fwhm)\n",
    "\n",
    "                # Collect guess parameters and subtract this guess gaussian from the data\n",
    "                guess = np.vstack((guess, (params[2], params[1], guess_std)))\n",
    "                peak_gauss = gaussian_function(xs, params[2], params[1], guess_std)\n",
    "\n",
    "            # center, height, width\n",
    "            lo_bound = [[guess[0][0] - 0.5 * guess[0][2], -np.inf, guess[0][2] - 2 * guess[0][2]],\n",
    "                        [guess[1][0] - 0.5 * guess[1][2], -np.inf, guess[1][2] - 2 * guess[1][2]],\n",
    "                        [guess[2][0] - 0.5 * guess[2][2], -np.inf, guess[2][2] - 2 * guess[2][2]],\n",
    "                        [guess[3][0] - 0.5 * guess[3][2], -np.inf, guess[3][2] - 2 * guess[3][2]],\n",
    "                        [guess[4][0] - 0.5 * guess[4][2], -np.inf, guess[4][2] - 2 * guess[4][2]]]\n",
    "\n",
    "            hi_bound = [[guess[0][0] + 0.5 * guess[0][2], np.inf, guess[0][2] + 2 * guess[0][2]],\n",
    "                        [guess[1][0] + 0.5 * guess[1][2], np.inf, guess[1][2] + 2 * guess[1][2]],\n",
    "                        [guess[2][0] + 0.5 * guess[2][2], np.inf, guess[2][2] + 2 * guess[2][2]],\n",
    "                        [guess[3][0] + 0.5 * guess[3][2], np.inf, guess[3][2] + 2 * guess[3][2]],\n",
    "                        [guess[4][0] + 0.5 * guess[4][2], np.inf, guess[4][2] + 2 * guess[4][2]]]\n",
    "\n",
    "            gaus_param_bounds = (tuple([item for sublist in lo_bound for item in sublist]),\n",
    "                                 tuple([item for sublist in hi_bound for item in sublist]))\n",
    "\n",
    "            # Flatten guess, for use with curve fit\n",
    "            guess_flat = np.ndarray.flatten(guess)\n",
    "\n",
    "            maxfev = 5000\n",
    "\n",
    "            # Check if any lower bound is not strictly less than its corresponding upper bound\n",
    "            skip_cycle = False\n",
    "            for lb, ub in zip(lo_bound, hi_bound):\n",
    "                if not all(l < u for l, u in zip(lb, ub)):\n",
    "                    print(f\"Skipping cycle #{cycle} due to invalid bounds.\")\n",
    "                    skip_cycle = True\n",
    "                    break\n",
    "\n",
    "            if skip_cycle:\n",
    "                continue\n",
    "\n",
    "            # If the check passes, proceed with fitting\n",
    "            try:\n",
    "                gaussian_params, _ = curve_fit(gaussian_function, xs, sig,\n",
    "                                               p0=guess_flat, maxfev=maxfev, bounds=gaus_param_bounds)\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Could not fit cycle #{cycle}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Reshape gaussian_params from 1,15 to 3, 5 to feed into create peak params\n",
    "            gaussian_params_reshape = gaussian_params.reshape((5, 3))\n",
    "\n",
    "            # Store the center, height, and width for each peak in the dictionary\n",
    "            for i, comp in enumerate(['p', 'q', 'r', 's', 't']):\n",
    "                ecg_output_dict[f'{comp}_center'][cycle] = gaussian_params_reshape[i, 0]\n",
    "                ecg_output_dict[f'{comp}_height'][cycle] = gaussian_params_reshape[i, 1]\n",
    "                ecg_output_dict[f'{comp}_width'][cycle] = gaussian_params_reshape[i, 2]\n",
    "\n",
    "            # Bycycle fit\n",
    "            peak_params = create_peak_params(xs, sig, gaussian_params_reshape)\n",
    "\n",
    "            # Initialize list of shape parameters\n",
    "            shape_params = np.empty((len(peak_params), 6))\n",
    "            peak_indices = np.empty((len(peak_params), 3))\n",
    "\n",
    "            for ii, peak in enumerate(peak_params):\n",
    "                # Get peak indices\n",
    "                start_index, peak_index, end_index = get_peak_indices(xs, sig, peak)\n",
    "\n",
    "                # If the peak indices could not be determined, set all shape params to NaN\n",
    "                if np.isnan(start_index) or np.isnan(end_index):\n",
    "                    shape_params[ii] = [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "                    peak_indices[ii] = [np.nan, np.nan, np.nan]\n",
    "                    continue\n",
    "\n",
    "                # Compute fwhm, rise-, and decay-time\n",
    "                fwhm = xs[end_index] - xs[start_index]\n",
    "                rise_time = xs[peak_index] - xs[start_index]\n",
    "                decay_time = xs[end_index] - xs[peak_index]\n",
    "\n",
    "                # Compute rise-decay symmetry\n",
    "                rise_decay_symmetry = rise_time / fwhm\n",
    "\n",
    "                # Compute sharpness using diff\n",
    "                half_mag = int(np.abs(peak[1] / 2))\n",
    "                half_mag_cropped_xval = np.argmin(np.abs(sig - half_mag))\n",
    "                left_index = peak_index - 15\n",
    "                right_index = peak_index + 15\n",
    "\n",
    "                sharpness_diff = np.mean(\n",
    "                    (sig[peak_index] - sig[left_index], sig[peak_index] + sig[right_index]))\n",
    "                sharpness_diff = np.abs(sharpness_diff)\n",
    "\n",
    "                # Compute sharpness using the derivative method\n",
    "                sharpness_deriv = calculate_sharpness_deriv(sig, peak_index)\n",
    "                sharpness_deriv = np.abs(sharpness_deriv)\n",
    "\n",
    "                # Collect results\n",
    "                shape_params[ii] = [fwhm, rise_time, decay_time, rise_decay_symmetry,\n",
    "                                    sharpness_diff, sharpness_deriv]\n",
    "                peak_indices[ii] = [start_index, peak_index, end_index]\n",
    "\n",
    "            fit = gaussian_function(xs, *gaussian_params)\n",
    "\n",
    "            # Calculate durations and intervals\n",
    "            ecg_output_dict['p_duration'][cycle] = ecg_output_dict['p_off'][cycle] - ecg_output_dict['p_on'][cycle]\n",
    "            ecg_output_dict['pr_interval'][cycle] = ecg_output_dict['q_on'][cycle] - ecg_output_dict['p_on'][cycle]\n",
    "            ecg_output_dict['pr_segment'][cycle] = ecg_output_dict['q_on'][cycle] - ecg_output_dict['p_off'][cycle]\n",
    "            ecg_output_dict['qrs_duration'][cycle] = ecg_output_dict['s_off'][cycle] - ecg_output_dict['q_on'][cycle]\n",
    "            ecg_output_dict['st_segment'][cycle] = ecg_output_dict['t_off'][cycle] - ecg_output_dict['s_off'][cycle]\n",
    "            ecg_output_dict['qt_interval'][cycle] = ecg_output_dict['t_off'][cycle] - ecg_output_dict['q_on'][cycle]\n",
    "\n",
    "            # Calculate R-R interval if there's a previous R peak\n",
    "            if previous_r_center is not None:\n",
    "                r_r_interval = r_center - previous_r_center\n",
    "                ecg_output_dict['rr_interval'][cycle] = r_r_interval\n",
    "            else:\n",
    "                ecg_output_dict['rr_interval'][cycle] = np.nan\n",
    "\n",
    "            # Calculate P-P interval if there's a previous P peak\n",
    "            if previous_p_center is not None:\n",
    "                p_p_interval = p_center - previous_p_center\n",
    "                ecg_output_dict['pp_interval'][cycle] = p_p_interval\n",
    "            else:\n",
    "                ecg_output_dict['pp_interval'][cycle] = np.nan\n",
    "\n",
    "            # Update the previous peaks' locations\n",
    "            previous_r_center = r_center\n",
    "            previous_p_center = p_center\n",
    "\n",
    "            r_squared = calc_r_squared(sig, fit)\n",
    "\n",
    "            # Add features to dictionary\n",
    "            ecg_output_dict['r_squared'][cycle] = r_squared\n",
    "\n",
    "            shape_params_flat = np.ndarray.flatten(shape_params)\n",
    "            ecg_output_dict['fwhm_p'][cycle], ecg_output_dict['rise_time_p'][cycle], ecg_output_dict['decay_time_p'][cycle], \\\n",
    "            ecg_output_dict['rise_decay_symmetry_p'][cycle], ecg_output_dict['sharpness_diff_p'][cycle], ecg_output_dict['sharpness_deriv_p'][cycle] = shape_params_flat[:6]\n",
    "            ecg_output_dict['fwhm_q'][cycle], ecg_output_dict['rise_time_q'][cycle], ecg_output_dict['decay_time_q'][cycle], \\\n",
    "            ecg_output_dict['rise_decay_symmetry_q'][cycle], ecg_output_dict['sharpness_diff_q'][cycle], ecg_output_dict['sharpness_deriv_q'][cycle] = shape_params_flat[6:12]\n",
    "            ecg_output_dict['fwhm_r'][cycle], ecg_output_dict['rise_time_r'][cycle], ecg_output_dict['decay_time_r'][cycle], \\\n",
    "            ecg_output_dict['rise_decay_symmetry_r'][cycle], ecg_output_dict['sharpness_diff_r'][cycle], ecg_output_dict['sharpness_deriv_r'][cycle] = shape_params_flat[12:18]\n",
    "            ecg_output_dict['fwhm_s'][cycle], ecg_output_dict['rise_time_s'][cycle], ecg_output_dict['decay_time_s'][cycle], \\\n",
    "            ecg_output_dict['rise_decay_symmetry_s'][cycle], ecg_output_dict['sharpness_diff_s'][cycle], ecg_output_dict['sharpness_deriv_s'][cycle] = shape_params_flat[18:24]\n",
    "            ecg_output_dict['fwhm_t'][cycle], ecg_output_dict['rise_time_t'][cycle], ecg_output_dict['decay_time_t'][cycle], \\\n",
    "            ecg_output_dict['rise_decay_symmetry_t'][cycle], ecg_output_dict['sharpness_diff_t'][cycle], ecg_output_dict['sharpness_deriv_t'][cycle] = shape_params_flat[24:30]\n",
    "\n",
    "        # Process the raw ECG signal (not the cleaned signal)\n",
    "        processed_data, _ = nk.ecg_process(ecg_notch, sampling_rate=1000)\n",
    "\n",
    "        # Access heart rate from the processed data\n",
    "        heart_rate = processed_data['ECG_Rate']\n",
    "\n",
    "        # Calculate average heart rate\n",
    "        average_heart_rate = heart_rate.mean()\n",
    "\n",
    "        rr_intervals = np.array(ecg_output_dict['rr_interval'])\n",
    "        rr_intervals = rr_intervals[~np.isnan(rr_intervals)]  # Ensure no NaN values\n",
    "\n",
    "        # Calculate HRV metrics\n",
    "        if len(rr_intervals) > 1:  # Need at least two intervals for RMSSD\n",
    "            sdnn = np.std(rr_intervals, ddof=1)\n",
    "            diff_nn_intervals = np.diff(rr_intervals)\n",
    "            squared_diff_nn_intervals = diff_nn_intervals ** 2\n",
    "            rmssd = np.sqrt(np.mean(squared_diff_nn_intervals))\n",
    "            nn50 = np.sum(np.abs(np.diff(rr_intervals)) > 50)\n",
    "        else:\n",
    "            sdnn, rmssd, nn50 = np.nan, np.nan, np.nan\n",
    "\n",
    "        # Add the calculated values to the dictionary for the first cycle\n",
    "        ecg_output_dict['Average_Heart_Rate'][0] = average_heart_rate\n",
    "        ecg_output_dict['SDNN'][0] = sdnn\n",
    "        ecg_output_dict['RMSSD'][0] = rmssd\n",
    "        ecg_output_dict['NN50'][0] = nn50\n",
    "\n",
    "        # Convert dictionary to DataFrame\n",
    "        ecg_output = pd.DataFrame(ecg_output_dict)\n",
    "\n",
    "        # Save output in new file\n",
    "        ecg_output.to_csv(os.path.join(results_dir, f\"{SUB_NUM}_ecg_output.csv\"))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing subject {SUB_NUM}: {e}\")\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Subject {SUB_NUM} processed in {elapsed_time:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-3:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/Users/morganfitzgerald/miniconda3/envs/ecgenv/lib/python3.10/multiprocessing/queues.py\", line 367, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "AttributeError: Can't get attribute 'process_subject' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dir_path = '/Users/morganfitzgerald/Projects/ecg_param/data/raw'\n",
    "    files_dat_dict, files_hea_dict = create_subject_file_mapping(dir_path)\n",
    "    results_dir = '../docs/saved_files/timedomain_results/'\n",
    "\n",
    "    # Create a list of arguments for each subject\n",
    "    subject_args = [\n",
    "        (SUB_NUM, dat_path, files_hea_dict[SUB_NUM], results_dir)\n",
    "        for SUB_NUM, dat_path in files_dat_dict.items()\n",
    "        if SUB_NUM in files_hea_dict\n",
    "    ]\n",
    "\n",
    "    # # Create a pool of workers and process each subject in parallel\n",
    "    # with mp.Pool(mp.cpu_count()) as pool:\n",
    "    #     pool.starmap(process_subject, subject_args)\n",
    "\n",
    "    # print(\"Processing complete.\")\n",
    "\n",
    "    # Create a pool of workers and process each subject in parallel using 4 cores\n",
    "    with mp.Pool(4) as pool:  # Use 4 cores\n",
    "        pool.starmap(process_subject, subject_args)\n",
    "\n",
    "    print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "print(mp.cpu_count())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecgenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
